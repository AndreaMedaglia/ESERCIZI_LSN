{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  </span> <span style=\"color:red\"> LEZIONE 11  </span>\n",
    "    \n",
    "## ESERCIZIO 11.2\n",
    "    \n",
    "###  Funzione polinomiale $f(x)=4-3x-2x^2+3x^3$ con $x \\in [-1,1]$.\n",
    "\n",
    "Facendo diversi tentativi, a fissate caratteristiche, di *layer* e numero di neuroni per ogni *layer*, si nota come si riesce ad ottenere una predizione migliore con un numero più alto di *layer*, ciascuno con un numero di neuroni simile agli altri, piuttosto che con pochi *layer* e un alto numero di neuroni, nonostante nel secondo caso ci siano molti più parametri da ottimizzare e le perdite siano comunque basse. Per esempio (con funzione di attivazione *elu*, ottimizzatore *sgd* e funzione perdita *mse*) ho provato con:\n",
    "\n",
    "- $2$ layer nascosti con rispettivamente $50$ e $30$ neuroni, per un totale di circa $1600$ parametri (Saved/Model_1).\n",
    "- $4$ layer nascosti con un numero di neuroni simile, rispettivamente $15$, $25$, $10$ e $5$, per un totale di circa $750$ parametri (Saved/Model_2).\n",
    "\n",
    "Tenendo invece fissi il numero di *layer* e di neuroni, in particolare usando il secondo caso precedente, ho provato a variare funzione di attivazione, con ottimizzatore *sgd* e funzione perdita *mse*. \n",
    "\n",
    "- Con *elu*, come nei casi precedenti, ho una buona precisione tranne nella zona $x \\in [0.75, 1]$, in cui $f(x)$ raggiunge un minimo locale e torna ad aumentare.\n",
    "- Con *relu* (impostazioni di default) invece nel range $x \\in [0.75, 1]$ il modello si comporta molto bene, seguendo $f(x)$. Pecca di precisione, però, nella zona del massimo locale. (Saved/Model_4).\n",
    "- Con *softplus* invece devo aumentare molto il numero $N_{epochs}$ perchè il rate di apprendimento è alto. Il grafico delle perdite è molto rumoroso, la precisione rispetto alla curva analitica è comunque minore rispetto ai casi precedenti. (Saved/Model_3).\n",
    "- Anche con *tanh* la zona del minimo locale sembra ben fittata.\n",
    "\n",
    "Date le considerazioni precedenti, ho provato ad usare entrambe le funzioni di attivazione *elu* (primo ed ultimo *layer*) e *relu* (*layer* centrali) nella speranza di poter combinare i \"punti di forza\" delle due. Il risultato, rispetto alla curva analitica $f(x)$ è sicuramente il migliore ottenuto, sia nella zona di massimo locale che in quella di minimo. (Saved/Model_5). Ho fatto lo stesso \"mischiando\" *relu* e *tanh* (Saved/Model_10), dovendo però aumentare il numero di iterazioni totali. I due modelli fittano grosso modo allo stesso modo.\n",
    "\n",
    "Partendo dal *setting* *elu+relu*, ho provato a variare le funzioni di ottimizzazione. \n",
    "- Con *adadelta* (Saved/Model_6) e *adagrad* (Saved/Model_7) il risultato non sembra cambiare in modo sostanziale. Peggiora forse nella zona del minimo locale (che in ogni caso è quella che dà più problemi). \n",
    "\n",
    "Tenendo quindi le scelte di Saved/Model_5, ho provato a cambiare la funzione di perdita.\n",
    "- Con *mae* perdo precisione nell'intorno del massimo locale, migliora nella zona minimo. (Saved/Model_8)\n",
    "- Con altre funzioni ottengo risultato non consistenti.\n",
    "\n",
    "Ho provato poi a guardare le predizioni fuori dal range di apprendimento del modello. Nelle zone fuori dall'intervallo $x \\in [-1, 1]$ il modello non riesce a predire la funzione $f(x)$, come del resto ci si può aspettare. La rete ha imparato su determinati dati in un determinato range. Fuori da quello, a meno di essere fortunati (caso lineare dell'Esercizio_11.1 per esempio).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Genero i dati per l'allenamento e la validazione della rete neurale: lungo l'asse $y$ \"sporco\" con un rumore gaussiano a media nulla e scorrelato a punti diversi. Mostro la funzione bersaglio e il set di dati per la validazione."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize']=[8, 5]\n",
    "\n",
    "# target parameters of f(x) = ax^3 + bx^2 + cx + d\n",
    "a = 3\n",
    "b = -2\n",
    "c = -3\n",
    "d = 4\n",
    "\n",
    "# generate training inputs\n",
    "np.random.seed(0)\n",
    "x_train = np.random.uniform(-1, 1, 1000)\n",
    "x_valid = np.random.uniform(-1, 1, 50)\n",
    "x_valid.sort()\n",
    "y_target = a*x_valid**3 + b*x_valid**2 + c*x_valid + d # ideal (target) function\n",
    "\n",
    "sigma = 0.2 # noise standard deviation, for the moment it is absent\n",
    "y_train = np.random.normal(a*x_train**3 + b*x_train**2 + c*x_train + d, sigma) \n",
    "y_valid = np.random.normal(a*x_valid**3 + b*x_valid**2 + c*x_valid + d, sigma)\n",
    "\n",
    "# plot training and target dataset\n",
    "\n",
    "plt.plot(x_valid, y_target, label='Target function')\n",
    "plt.scatter(x_valid, y_valid, color='r', label='Validation data')\n",
    "plt.legend(loc='upper right')\n",
    "plt.grid(True); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Genero la rete neurale scegliendo il numero e il tipo di *layer* con un rispettivo numero di neuroni (l'ultimo *layer* deve avere un solo neurone). Scelgo poi le funzioni di ottimizzazione, di perdita e la metrica. Inserisco anche una funzione di attivazione *elu*. Stampo il \"riassunto\" della rete che ho appena creato. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.utils import get_custom_objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compose the NN model\n",
    "model = tf.keras.Sequential()\n",
    "model.add(Dense(15, input_shape=(1,), activation='relu')) \n",
    "model.add(Dense(25, input_shape=(1,), activation='tanh')) \n",
    "model.add(Dense(10, input_shape=(1,), activation='relu')) \n",
    "model.add(Dense(5, input_shape=(1,), activation='tanh'))  \n",
    "model.add(Dense(1, input_shape=(1,), activation='relu'))  #layer finale con 1 neurone\n",
    "\n",
    "# compile the model choosing optimizer, loss and metrics objects\n",
    "model.compile(optimizer='sgd', loss='mse', metrics=['mse'])\n",
    "\n",
    "# get a summary of our composed model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Alleno la rete neurale: prende in entrata, per ogni iterazione, i dati di allenamento che ho generato prima e cerca i parametri che meglio descrivono la funzione dalla quale sono stati generati, minimizzando la funzione perdita.  \n",
    "\n",
    "#### Stampo anche i risultati della validazione, cioè del test che faccio sul mio modello (con i dati di validazione generati in precedenza) per vedere quanto è buono il risultato. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the model using training dataset\n",
    "# over 10 epochs of 32 batch size each\n",
    "# report training progress against validation data\n",
    "history = model.fit(x=x_train, y=y_train, \n",
    "          batch_size=32, epochs=100,\n",
    "          shuffle=True, # a good idea is to shuffle input before at each epoch\n",
    "          validation_data=(x_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stampa i pesi del modello, scommentare in caso\n",
    "# model.get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testo il modello finale che ho generato sui dati di validazione e sulla curva esatta per vedere quanto è buono"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate model\n",
    "score = model.evaluate(x_valid, y_valid, batch_size=32, verbose=1)\n",
    "\n",
    "# print performance\n",
    "print()\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate model with the exact curve\n",
    "score = model.evaluate(x_valid, y_target, batch_size=32, verbose=1)\n",
    "\n",
    "# print performance\n",
    "print()\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Riporto l'andamento delle perdite in relazione alle iterazioni per l'allenamento e il test sui dati di validazione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look into training history\n",
    "# Plot training & validation loss values\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ora sono pronto per far predire dati sulla base del modello che ho creato e li confronto con la curva esatta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_predicted = np.random.uniform(-1, 1, 1000)\n",
    "y_predicted = model.predict(x_predicted)\n",
    "plt.scatter(x_predicted, y_predicted,color='r')\n",
    "plt.plot(x_valid, y_target)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Salvare il Modello"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### CELLA PER SALVARE IL MODELLO: CAMBIARE NOME, IN CASO ##########\n",
    "\n",
    "save_model_path='Saved/Model_10'\n",
    "model.save(filepath=save_model_path, include_optimizer=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Caricare Modello salvato e stampare le caratteristiche"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CARICARE UN MODELLO SALVATO #\n",
    "# ricordarsi di compilare i primi 2 blocchi di questo jupyter #\n",
    "\n",
    "from keras.models import load_model\n",
    "from keras.utils import CustomObjectScope\n",
    "from keras.initializers import glorot_uniform\n",
    "\n",
    "with CustomObjectScope({'GlorotUniform': glorot_uniform()}):\n",
    "        model_old = load_model('./Saved/Model_2')\n",
    "\n",
    "\n",
    "# stampo le caratteristiche del modello salvato #\n",
    "model_old.summary()\n",
    "\n",
    "print()\n",
    "print()\n",
    "# evaluate model\n",
    "print('Loss e accuracy sui dati di validazione')\n",
    "print()\n",
    "score = model_old.evaluate(x_valid, y_valid, batch_size=32, verbose=1)\n",
    "# print performance\n",
    "print()\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "print()\n",
    "print()\n",
    "# evaluate model with the exact curve\n",
    "print('Loss e accuracy sulla funzione bersagio')\n",
    "print()\n",
    "score = model_old.evaluate(x_valid, y_target, batch_size=32, verbose=1)\n",
    "print()\n",
    "# print performance\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predizioni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_predicted = np.random.uniform(-1, 1, 100)\n",
    "y_predicted = model_old.predict(x_predicted)\n",
    "plt.scatter(x_predicted, y_predicted,color='r')\n",
    "plt.plot(x_valid, y_target)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
